---
title: "06 â€” Feature Scaling & Anti-Leakage (Ames Housing)"
date: 2025-09-20
number: 6
status: "Completada"
tags: [Feature Scaling, StandardScaler, RobustScaler, MinMaxScaler, Anti-leakage, Pipeline, Cross-Validation, Yeo-Johnson, QuantileTransformer, Ames Housing]
notebook: docs/evidencias/Aurrecochea-PrÃ¡ctica6.ipynb
drive_viz: â€”
dataset: "Ames Housing â€” Kaggle"
time_est: "3 h 30 m"
time_spent: "â€”"
---

# {{ page.meta.title }}

<span class="pill">{{ page.meta.status }}</span>
<span class="pill">#{{ page.meta.number }}</span>
{% if page.meta.tags %}{% for t in page.meta.tags %}<span class="pill">{{ t }}</span>{% endfor %}{% endif %}

!!! abstract "Resumen ejecutivo"
    **Objetivo:** evaluar la necesidad de escalado en Ames Housing; aplicar y comparar distintos escaladores (**MinMax**, **Standard**, **Robust**); probar transformaciones avanzadas (**log1p**, **Yeo-Johnson**, **QuantileTransformer**); y validar la importancia de usar *pipelines* para evitar **data leakage**.  
    **Scope:** selecciÃ³n de 5 *features* numÃ©ricas (`Lot Area`, `Overall Qual`, `Year Built`, `1st Flr SF`, `Gr Liv Area`) con *target* `SalePrice`.  
    **Resultado:** *Pipeline* recomendado = `log1p` en variables muy sesgadas â†’ imputaciÃ³n (mediana / One-Hot) â†’ `StandardScaler` â†’ `LinearRegression`, con **RÂ² = 0.776 Â± 0.033 (5-fold)**.  

---

## Contexto
Los modelos sensibles a distancias o magnitudes (KNN, SVM, regresiones lineales con regularizaciÃ³n) requieren escalado para garantizar estabilidad y comparabilidad. Esta prÃ¡ctica explora el impacto de diferentes transformaciones y la implementaciÃ³n de *pipelines* anti-leakage con validaciÃ³n cruzada.

## Objetivos
- [x] Detectar variables con escalas muy dispares.  
- [x] Evaluar transformaciones para reducir sesgo y *outliers*.  
- [x] Implementar y comparar distintos escaladores.  
- [x] Demostrar con mÃ©tricas la importancia de anti-leakage.  
- [x] Validar resultados con **cross-validation** estable.  

---

## Actividades (con tiempos estimados)

| Actividad | Estimado | Real | Nota |
|---|---:|---:|---|
| AnÃ¡lisis inicial de escalas | 15 m | **20 m** | Ratio mÃ¡x/min en cada feature. |
| Outliers y sesgo | 25 m | **35 m** | Conteo con IQR y Z-score; skewness. |
| Transformaciones avanzadas | 30 m | **40 m** | log1p, Yeo-Johnson, QuantileTransformer. |
| ComparaciÃ³n de escaladores | 30 m | **38 m** | Standard vs. MinMax vs. Robust. |
| Anti-leakage (demos) | 30 m | **42 m** | M1/M2 vs Pipeline + CV. |
| ValidaciÃ³n final | 30 m | **37 m** | Cross-validation 5 folds; RÂ², RMSE. |
| Informe y reflexiÃ³n | 20 m | **25 m** | RedacciÃ³n final y recomendaciones. |

> **Totales** â€” Estimado: **3 h 00 m** Â· Real: **3 h 57 m** Â· Î”: **+57 m** (**+31.7%**).

---

## Desarrollo

### 1) AnÃ¡lisis de escalas
- `Lot Area`: ratio mÃ¡x/min â‰ˆ **165.6** â†’ escala mÃ¡s dispareja.  
- `SalePrice`: ratio â‰ˆ **59**.  
â†’ Justifica escalado, sobre todo para modelos sensibles.

### 2) Outliers y sesgo
- En `SalePrice`: IQR detecta **137** outliers, Z-score **45**.  
- **CorrecciÃ³n aplicada:** los cambios en conteo tras el escalado no se deben al escalador, sino a trabajar sobre distinto *split*. Es clave comparar *outliers* siempre sobre el mismo subconjunto.

### 3) Transformaciones avanzadas
- `Lot Area`: skew â‰ˆ **12.8** â†’ con `log1p` baja a **â€“0.49**.  
- `Yeo-Johnson`: reduce skew de `SalePrice` a â‰ˆ 0, y baja outliers (IQR 137â†’59, Z-score 45â†’20).  
- `QuantileTransformer`: normaliza bien distribuciones sesgadas.  
- **Normalizer/MaxAbs**: no Ãºtiles en este caso.

### 4) Anti-leakage (demos)
- **M1 (con leakage, single split):** RMSE â‰ˆ 32185.  
- **M2 (sin leakage manual, single split):** RMSE â‰ˆ 32287.  
- **M3 (pipeline + 5-fold CV):** RMSE â‰ˆ 30651.  
â†’ ConclusiÃ³n: el pipeline con CV no es â€œmÃ¡s optimistaâ€, sino mÃ¡s **estable y honesto**.

### 5) ValidaciÃ³n final
- Modelo: `StandardScaler` + `LinearRegression`.  
- **RÂ² = 0.776 Â± 0.033** (5 folds).  
- Baseline (DummyRegressor): mucho menor, confirma el valor agregado.

---

## MÃ©tricas / Indicadores

| Indicador | Valor/ObservaciÃ³n |
|---|---|
| Ratio mÃ¡x/min (`Lot Area`) | 165.6 |
| Skew inicial (`Lot Area`) | 12.8 |
| Skew tras log1p | â€“0.49 |
| Outliers IQR/Z-score (`SalePrice`) | 137 / 45 |
| Outliers tras Yeo-Johnson | 59 / 20 |
| RMSE M1/M2/M3 | 32185 / 32287 / 30651 |
| RÂ² final (5-fold) | 0.776 Â± 0.033 |

---

## Decisiones clave (ADR-lite)
- Escalado necesario en `Lot Area` y `SalePrice`.  
- `log1p` o Yeo-Johnson en variables con skew alto.  
- Mantener `StandardScaler` como opciÃ³n por defecto.  
- Uso de *pipelines* anti-leakage con CV obligatorio.  
- Baseline (`DummyRegressor`) como punto de comparaciÃ³n.

!!! warning "Correcciones aplicadas"
    - La reducciÃ³n de *outliers* al escalar no es real: se debe a cambios de muestra. Corregido en el anÃ¡lisis.  
    - La conclusiÃ³n sobre â€œoptimismoâ€ fue ajustada: no es que el pipeline sea mÃ¡s optimista, sino que provee estimaciones mÃ¡s robustas.  
    - Se recomienda **imputaciÃ³n** y **One-Hot Encoding** en pipeline, en lugar de *drop* de filas con NaNs.

---

## Evidencias
- [**Notebook (.ipynb)**](../../evidencias/Aurrecochea-PrÃ¡ctica6.ipynb)
- [**Notebook (.ipynb) de ProfundizaciÃ³n en el anÃ¡lisis (BONUS)**](../../evidencias/Aurrecochea-PrÃ¡ctica6Bonus.ipynb)

<div class="cards-grid media">

  <div class="card">
    <img src="../../assets/PrÃ¡ctica6/boxplots.png" alt="Boxplots de variables numÃ©ricas" loading="lazy">
    <div class="caption">
      Boxplots de escalas
      <small>ComparaciÃ³n de magnitudes en Lot Area, SalePrice y otras features</small>
    </div>
  </div>

  <div class="card">
    <img src="../../assets/PrÃ¡ctica6/comparacionlogs.png" alt="Distribuciones antes y despuÃ©s de log1p" loading="lazy">
    <div class="caption">
      TransformaciÃ³n log1p
      <small>ReducciÃ³n de skewness en Lot Area tras aplicar logaritmo</small>
    </div>
  </div>

  <div class="card">
    <img src="../../assets/PrÃ¡ctica6/histogramas.png" alt="Histogramas de detecciÃ³n de outliers" loading="lazy">
    <div class="caption">
      Histogramas de outliers
      <small>ComparaciÃ³n de detecciÃ³n por IQR y Z-score</small>
    </div>
  </div>

</div>

## Transformations & Scalers (evidencias)

<div class="cards-grid media">

  <div class="card">
    <img src="../../assets/PrÃ¡ctica6/FunctionTransformer.png" alt="FunctionTransformer con log1p aplicado a variables sesgadas" loading="lazy">
    <div class="caption">
      FunctionTransformer (log1p)
      <small>Para colas largas y valores 0; reduce skew sin desescalar magnitudes.</small>
    </div>
  </div>

  <div class="card">
    <img src="../../assets/PrÃ¡ctica6/YeoJohnson.png" alt="Power transform Yeo-Johnson para normalizar distribuciones" loading="lazy">
    <div class="caption">
      PowerTransformer â€” Yeo-Johnson
      <small>Normaliza incluso con ceros/negativos; Ãºtil cuando log1p no alcanza.</small>
    </div>
  </div>

  <div class="card">
    <img src="../../assets/PrÃ¡ctica6/QuantileTransformer.png" alt="QuantileTransformer hacia distribuciÃ³n Normal" loading="lazy">
    <div class="caption">
      QuantileTransformer (â†’ Normal)
      <small>Hace monotÃ³nica y ~Normal la variable; robusto a outliers, cambia distancias.</small>
    </div>
  </div>

  <div class="card">
    <img src="../../assets/PrÃ¡ctica6/MaxAbsScaler.png" alt="MaxAbsScaler escala por valor absoluto mÃ¡ximo" loading="lazy">
    <div class="caption">
      MaxAbsScaler
      <small>Escala a [-1,1] sin centrar; bueno para datos dispersos/sparse.</small>
    </div>
  </div>

  <div class="card">
    <img src="../../assets/PrÃ¡ctica6/NormalizerL2.png" alt="Normalizer L2 reescala filas a norma unitaria" loading="lazy">
    <div class="caption">
      Normalizer (L2)
      <small>Normaliza filas (vectores de muestra); Ãºtil en similitud/coseno, no para tabulares clÃ¡sicos.</small>
    </div>
  </div>

</div>

---

## ComparaciÃ³n de transformers investigados

| Transformer | Tipo de transformaciÃ³n | Ventajas | Limitaciones / CuÃ¡ndo NO usarlo |
|-------------|------------------------|----------|--------------------------------|
| **FunctionTransformer (log1p)** | LogarÃ­tmica simple (x â†’ log(1+x)) | FÃ¡cil de interpretar, comprime colas largas, mantiene orden | Solo para x â‰¥ 0; no corrige totalmente asimetrÃ­as extremas |
| **Yeo-Johnson (PowerTransformer)** | TransformaciÃ³n de potencia paramÃ©trica | Funciona con ceros y negativos, reduce skew, aproxima a Normal | Menos interpretable, puede distorsionar relaciones lineales |
| **QuantileTransformer (â†’ Normal)** | MonÃ³tona basada en cuantiles | Elimina asimetrÃ­a, distribuye ~Normal, muy robusto a outliers | Distancias absolutas dejan de ser significativas; pierde interpretaciÃ³n original |
| **MaxAbsScaler** | Escala cada feature dividiendo por su valor absoluto mÃ¡ximo | Conserva dispersiÃ³n relativa, Ãºtil en datos dispersos (*sparse*) | No centra en media 0, no corrige outliers, no afecta skew |
| **Normalizer (L2)** | Reescala cada fila a norma unitaria | Ãštil para similitud coseno / ML basado en Ã¡ngulos | No es apropiado para tabulares clÃ¡sicos; distorsiona magnitudes absolutas |

!!! tip "SÃ­ntesis"
    - Para variables **sesgadas** â†’ `log1p` o `Yeo-Johnson`.  
    - Para variables con **colas extremas y outliers fuertes** â†’ `QuantileTransformer`.  
    - Para **datos dispersos** (ej. texto vectorizado) â†’ `MaxAbsScaler`.  
    - Para **mÃ©tricas angulares** (ej. KNN con coseno) â†’ `Normalizer L2`.  
    - Como **default general en tabulares** â†’ `StandardScaler` (fuera de esta tabla, pero quedÃ³ como baseline final).



---

## Cuestionario y respuestas

1. **Â¿QuÃ© variables requieren escalado y por quÃ©?**  
   `Lot Area` (ratio 165.6) y `SalePrice` (ratio 59) tienen escalas muy dispares â†’ necesario para modelos sensibles a magnitud.

2. **Â¿QuÃ© pasa con los outliers al aplicar escalado?**  
   El escalado no elimina outliers; los cambios en conteo se debieron a trabajar sobre distinto *split*. Para reducir sesgo se recomienda usar log/Yeo-Johnson o winsorizaciÃ³n.

3. **Â¿QuÃ© transformaciones mejoraron mÃ¡s la forma de las distribuciones?**  
   - `log1p` en `Lot Area` (skew 12.8 â†’ â€“0.49).  
   - `Yeo-Johnson` y `QuantileTransformer` en `SalePrice`, que bajaron outliers y normalizaron la distribuciÃ³n.

4. **Â¿QuÃ© demostrÃ³ el ejercicio de leakage?**  
   Que aplicar transformaciones antes del split genera estimaciones poco realistas. Solo con *pipelines* y CV se logra evaluar sin fuga de informaciÃ³n.

5. **Â¿QuÃ© protocolo de validaciÃ³n fue mÃ¡s confiable?**  
   El **Pipeline + 5-fold CV**, con RÂ² = 0.776 Â± 0.033. MÃ¡s estable y menos dependiente de un Ãºnico split.

6. **RecomendaciÃ³n final de pipeline**  
   - `log1p` en variables sesgadas.  
   - ImputaciÃ³n (mediana para numÃ©ricas, constante/One-Hot para categÃ³ricas).  
   - `StandardScaler`.  
   - Modelo lineal simple como baseline, extensible a KNN/SVR.  

---

!!! note "ReflexiÃ³n"
    Esta prÃ¡ctica me permitiÃ³ comprobar que **el escalado y las transformaciones deben justificarse con mÃ©tricas** (ratio, skew, outliers). TambiÃ©n confirmÃ© que **el anti-leakage es innegociable**: un pipeline bien armado no solo garantiza reproducibilidad, sino que cambia radicalmente la validez de los resultados. 

---

## PrÃ³ximos pasos
- [ ] Probar escaladores en KNN, SVR y Random Forest.  
- [ ] Evaluar `TransformedTargetRegressor` para aplicar log al target.  
- [ ] Medir con mÃºltiples mÃ©tricas (RMSE, MAE, MAPE).  
- [ ] Agregar winsorizaciÃ³n para casos extremos en Lot Area.

---
## De cara a futuros proyectos:
- Voy a incorporar **TransformedTargetRegressor** para transformar tambiÃ©n el *target* en datasets sesgados.  
- Planeo probar **combinaciones de transformers** (ej. log1p + RobustScaler) para casos con outliers extremos.  
- Voy a documentar cada decisiÃ³n en un **ADR-lite** (mini registro de decisiones), lo que facilita replicar o defender el pipeline en entornos profesionales.  
- Finalmente, pienso incluir estas comparaciones en un **repositorio de â€œrecetas de preprocesamientoâ€** propio, para reutilizarlas rÃ¡pidamente en proyectos de machine learning.

## ğŸ† MI CHECKLIST PERSONAL PARA PROYECTOS DE DATOS:

- [ ] 1. Â¿Las features estÃ¡n en escalas muy diferentes?
- [ ] 2. Â¿Mi proceso necesita escalado?  
- [ ] 3. Â¿Hay outliers evidentes? â†’ Â¿RobustScaler?
- [ ] 4. Â¿Datos muy sesgados? â†’ Â¿Log transform?
- [ ] 5. Â¿Estoy usando Pipeline? â†’ SIEMPRE (anti-leakage)
- [ ] 6. Â¿Split ANTES de transformar? â†’ OBLIGATORIO
- [ ] 7. Â¿Cross-validation honesta? â†’ Pipeline + CV
- [ ] 8. Â¿Resultados realistas vs optimistas? â†’ Detectar leakage
- [ ] 9. Â¿DocumentÃ© mi elecciÃ³n de transformadores?
- [ ] 10. Â¿Mi pipeline es reproducible?
