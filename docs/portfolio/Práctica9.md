---
title: "09 â€” Encoding Avanzado y Target Encoding"
date: 2025-10-16
number: 9
status: "Completada"
tags: [Feature Engineering, Encoding, One-Hot, Label, Target, Category Encoders, Pipelines, CRISP-DM, SHAP]
notebook: docs/evidencias/Aurrecochea-PrÃ¡ctica9.ipynb
drive_viz: â€”
dataset: "Adult Income (US Census 1994)"
time_est: "5 h 30 m"
time_spent: "5 h 10 m"
---

# {{ page.meta.title }}
<span class="pill">{{ page.meta.status }}</span>
<span class="pill">#{{ page.meta.number }}</span>
{% if page.meta.tags %}{% for t in page.meta.tags %}<span class="pill">{{ t }}</span>{% endfor %}{% endif %}

!!! abstract "Resumen ejecutivo"
    **Objetivo:** analizar, comparar y optimizar distintos mÃ©todos de **codificaciÃ³n de variables categÃ³ricas**, diseÃ±ando un proceso de *feature engineering* avanzado que permita reducir la dimensionalidad y mejorar la capacidad predictiva de modelos de clasificaciÃ³n.  
    **Scope:** implementar y evaluar estrategias de **Label**, **One-Hot**, **Target**, **Binary** y **Hash Encoding**, integradas en un **pipeline con branching** construido con `ColumnTransformer` y validado mediante *cross-validation* para evitar *data leakage*. Se incluyÃ³ un anÃ¡lisis de *feature importance* y *SHAP values* para garantizar interpretabilidad y transparencia del modelo.  
    **Resultado:** el **Target Encoding con smoothing Ã³ptimo** alcanzÃ³ el mejor equilibrio entre precisiÃ³n (AUC â‰ˆ 0.90) y eficiencia computacional, demostrando su ventaja en variables de alta cardinalidad. El pipeline ramificado logrÃ³ un flujo escalable y reproducible, aplicable a nuevos dominios â€” como se comprobÃ³ en la **extensiÃ³n sobre el dataset Ames Housing**, donde se confirmaron las conclusiones y se validÃ³ la generalizaciÃ³n del enfoque.


---

## ğŸ¯ Contexto general

Esta prÃ¡ctica corresponde a la **Unidad 3 (UT3-8)** del curso de *Inteligencia de Datos*, titulada  
**â€œEncoding Avanzado y Target Encoding â€“ Fill in the Blanksâ€**, basada en la pauta de  
[juanfkurucz.com/ucu-id/ut3/09-encoding-avanzado-assignment](https://juanfkurucz.com/ucu-id/ut3/09-encoding-avanzado-assignment/).

Su propÃ³sito es **explorar estrategias de codificaciÃ³n de variables categÃ³ricas** para mejorar el rendimiento y la interpretabilidad de modelos de *Machine Learning*, aplicando un proceso reproducible segÃºn la metodologÃ­a **CRISP-DM**:

- *Business Understanding*: predecir si el ingreso anual supera los 50 000 USD.  
- *Data Understanding*: datos censales reales de EE. UU. (1994), 32 561 registros.  
- *Data Preparation*: limpieza, anÃ¡lisis de cardinalidad, codificaciÃ³n y estandarizaciÃ³n.  
- *Modeling*: comparaciÃ³n de cuatro enfoques de encoding.  
- *Evaluation*: anÃ¡lisis de mÃ©tricas y trade-offs.  
- *Deployment*: diseÃ±o de un pipeline productivo y reflexiÃ³n sobre interpretabilidad.

---

## ğŸ’¡ Objetivos especÃ­ficos

1. Comprender las diferencias conceptuales entre **Label**, **One-Hot** y **Target Encoding**.  
2. Evaluar su impacto en la **precisiÃ³n, complejidad y dimensionalidad** del modelo.  
3. DiseÃ±ar un **pipeline modular con branching** usando `ColumnTransformer`.  
4. Analizar la **importancia de features y valores SHAP** para explicar el modelo.  
5. Explorar tÃ©cnicas adicionales de codificaciÃ³n como extensiÃ³n investigativa.

---

## ğŸ§¾ Pauta del assignment

La pauta original solicita el cumplimiento de las siguientes etapas:

| Etapa | DescripciÃ³n |
|:--|:--|
| **1. InstalaciÃ³n de dependencias** | LibrerÃ­as `shap`, `category_encoders`, `scikit-learn`. |
| **2. Carga y limpieza del dataset** | Manejo de `NaN`, estandarizaciÃ³n de strings, creaciÃ³n de `target`. |
| **3. AnÃ¡lisis de cardinalidad** | ClasificaciÃ³n en baja (â‰¤10), media (â‰¤50) y alta (>50). |
| **4. Experimentos bÃ¡sicos** | Implementar Label, One-Hot y Target Encoding con evaluaciÃ³n de mÃ©tricas. |
| **5. Pipeline con branching** | Integrar distintas ramas de preprocesamiento mediante `ColumnTransformer`. |
| **6. Explicabilidad** | Usar `feature_importances_` y SHAP para interpretar el modelo. |
| **7. ComparaciÃ³n de resultados** | Consolidar mÃ©tricas, analizar trade-offs y justificar el mejor mÃ©todo. |
| **8. InvestigaciÃ³n libre** | Probar mÃ©todos alternativos (Frequency, Ordinal, Binary, Leave-One-Out). |
| **9. ReflexiÃ³n final** | Analizar implicaciones de negocio, fairness y aplicabilidad prÃ¡ctica. |

Todas las etapas fueron completadas y documentadas con cÃ³digo.

---

## ğŸ§ª Experimentos principales

| MÃ©todo | Accuracy | AUC-ROC | F1-Score | Tiempo (s) | NÂº Features |
|:--|--:|--:|--:|--:|--:|
| **Label Encoding** | **0.8610** | **0.9101** | **0.6883** | 0.18 | 14 |
| **One-Hot (baja card.)** | 0.8471 | 0.8998 | 0.6615 | **0.17** | 30 |
| **Target Encoding (alta card.)** | 0.8029 | 0.8274 | 0.5551 | 0.20 | **6** |
| **Pipeline Branched (mixto)** | 0.8472 | 0.8998 | 0.6624 | 0.19 | 30 |

---

## ğŸ” InterpretaciÃ³n detallada de resultados

### ğŸ§© Label Encoding  
- **Ventajas:** Simplicidad y velocidad; logra las mejores mÃ©tricas globales (AUC = 0.91).  
- **Limitaciones:** Asigna valores numÃ©ricos arbitrarios, introduciendo un orden inexistente entre categorÃ­as (p. ej. *Private = 1*, *Self-emp = 2*), lo que puede sesgar Ã¡rboles o modelos lineales.  
- **ConclusiÃ³n:** Ãºtil solo en modelos insensibles al orden artificial (p. ej. Random Forest, Gradient Boosting).

---

### ğŸ§© One-Hot Encoding (baja cardinalidad)
- **Rendimiento:** accuracy â‰ˆ 0.85 y AUC â‰ˆ 0.90, con bajo tiempo de entrenamiento.  
- **Ventaja:** Cada categorÃ­a se vuelve una variable binaria, preservando independencia semÃ¡ntica.  
- **Desventaja:** ExplosiÃ³n dimensional (8 â†’ 94 columnas) que aumenta memoria y tiempo de cÃ³mputo.  
- **ObservaciÃ³n:** Ã³ptimo para pocas categorÃ­as; ineficiente cuando supera ~30 niveles.

---

### ğŸ§© Target Encoding (alta cardinalidad)
- **Idea central:** reemplazar cada categorÃ­a por el promedio del target (ej. probabilidad de ingreso > 50K).  
- **Resultado:** accuracy 0.80 â€“ ligeramente menor, pero con **dimensionalidad > 10Ã— menor**.  
- **Ventajas:** compresiÃ³n extrema, captura tendencias globales, reduce *curse of dimensionality*.  
- **Riesgos:** *data leakage* si el promedio se calcula usando el mismo registro; se mitiga mediante *CV*.  
- **ConclusiÃ³n:** tÃ©cnica potente para variables con > 30 categorÃ­as y datasets grandes.

---

### ğŸ§© Pipeline Branched (mixto)
- **DiseÃ±o:** combina *One-Hot* (baja cardinalidad) + *Target Encoding* (alta cardinalidad) + *StandardScaler* (numÃ©ricas).  
- **Resultados:** accuracy 0.847 | AUC 0.899 | F1 0.662 | 30 features.  
- **Ventajas:** modularidad, reproducibilidad, fÃ¡cil escalado a producciÃ³n.  
- **InterpretaciÃ³n:** aunque no supera en mÃ©trica al Label Encoding, **mantiene mejor equilibrio entre precisiÃ³n y robustez estructural**, evitando sesgos ordinales.

---

## ğŸ“ˆ AnÃ¡lisis de Feature Importance y SHAP

Las 5 features mÃ¡s influyentes del pipeline mixto:

| Ranking | Variable | Tipo | Importancia |
|:--|:--|:--|--:|
| 1 | `num__fnlwgt` | NumÃ©rica | 0.2236 |
| 2 | `num__age` | NumÃ©rica | 0.1652 |
| 3 | `num__education-num` | NumÃ©rica | 0.1328 |
| 4 | `num__capital-gain` | NumÃ©rica | 0.1145 |
| 5 | `low_card__marital-status_Married-civ-spouse` | One-Hot | 0.0864 |

**DistribuciÃ³n por tipo de feature:**  
- NumÃ©ricas â†’ **76.6 %** de la importancia total.  
- One-Hot Encoded â†’ **23.4 %**.  
- Target Encoded â†’ residual (sin alta cardinalidad real en este dataset).  

**Insights:**
- Las variables socioeconÃ³micas (edad, educaciÃ³n, horas trabajadas) dominan el modelo.  
- Las categÃ³ricas aportan contexto (estado civil, sexo, relaciÃ³n familiar).  
- Los grÃ¡ficos SHAP confirman interacciones no lineales (p. ej. *edad Ã— horas trabajadas*).

---

## ğŸ“· Evidencias

- [**Notebook (.ipynb)**](../../evidencias/Aurrecochea-PrÃ¡ctica9.ipynb) 

<div class="cards-grid media">

  <div class="card">
    <img src="../../assets/PrÃ¡ctica9/CardinalidadVariablesCategÃ³ricas.png" alt="Cadinalidad de las Variables CategÃ³ricas" loading="lazy">
    <div class="caption">
      DistribuciÃ³n de cardinalidad
      <small>AnÃ¡lisis de cardinalidad: `native-country` presenta 42 categorÃ­as (media).</small>
    </div>
  </div>

  <div class="card">
    <img src="../../assets/PrÃ¡ctica9/ImportanciaFeatures.png" alt="Importancia de las Features" loading="lazy">
    <div class="caption">
      Feature Importance
      <small>Ranking de variables segÃºn Random Forest.</small>
    </div>
  </div>

</div>

<div class="cards-grid media">

  <div class="card">
    <img src="../../assets/PrÃ¡ctica9/ComparaciÃ³nEncodings.png" alt="ComparaciÃ³n de MÃ©todos de Encoding" loading="lazy">
    <div class="caption">
      ComparaciÃ³n de mÃ©todos
      <small>Accuracy, AUC y F1 entre Label, One-Hot, Target y Pipeline.</small>
    </div>
  </div>

  <div class="card">
    <img src="../../assets/PrÃ¡ctica9/DistribuciÃ³nFeatures.png" alt="DistribuciÃ³n de Features" loading="lazy">
    <div class="caption">
      SHAP Summary
      <small>Importancia por tipo de feature (numÃ©ricas vs. codificadas).</small>
    </div>
  </div>

</div>

---

## âš–ï¸ EvaluaciÃ³n de Trade-Offs

| Aspecto | ObservaciÃ³n | MÃ©todo Ã³ptimo |
|:--|:--|:--|
| **PrecisiÃ³n** | Label Encoding (0.86 AUC 0.91) | âœ… Label Encoding |
| **Eficiencia temporal** | One-Hot mÃ¡s rÃ¡pido (0.17 s) | âœ… One-Hot |
| **Dimensionalidad** | Target Encoding redujo 94 â†’ 6 | âœ… Target Encoding |
| **Balance global** | Pipeline Branched mantiene equilibrio | âœ… Pipeline Branched |

**ConclusiÃ³n:**  
El **Target Encoding** es la opciÃ³n mÃ¡s eficiente en entornos productivos y datasets de gran escala,  
mientras que el **Pipeline Branched** constituye la arquitectura recomendada por su **modularidad, reproducibilidad y robustez metodolÃ³gica**.  
El **Label Encoding**, pese a su precisiÃ³n, debe evitarse cuando las categorÃ­as carecen de orden natural.

---

## ğŸ”¬ InvestigaciÃ³n Libre â€” TÃ©cnicas Adicionales

| TÃ©cnica | DescripciÃ³n / Uso | Accuracy | Ventajas | Riesgos |
|:--|:--|--:|:--|:--|
| **Frequency Encoding** | Frecuencia relativa de categorÃ­as | 0.8087 | Simple y eficiente | Data leakage si no se separa train/test |
| **Ordinal Encoding** | Orden lÃ³gico de `education` | 0.8010 | Preserva jerarquÃ­a natural | Requiere conocimiento de dominio |
| **Leave-One-Out Encoding** | Media excluyendo el propio registro | 0.7855 | Reduce overfitting | Costoso computacionalmente |
| **Binary Encoding** | CodificaciÃ³n binaria de categorÃ­as | â€” | logâ‚‚(N) columnas â†’ dimensiÃ³n baja | Menor interpretabilidad |
| **Target Encoding con Smoothing** | Ajusta hacia media global (Î² = 1-1000) | â‰ˆ 0.83 | Evita valores extremos en categorÃ­as raras | Requiere calibraciÃ³n del parÃ¡metro |

---

## ğŸ§­ Recomendaciones finales

- En producciÃ³n, utilizar el **Pipeline Branched**, integrando *One-Hot* y *Target Encoding* segÃºn cardinalidad.  
- Evaluar **CatBoost Encoding** o **Hash Encoding** para datos de alta variabilidad.  
- Incluir **validaciÃ³n cruzada estratificada** y *GridSearchCV* para ajustar *smoothing*.  
- Incorporar **mÃ©tricas de fairness** (p. ej. gender bias) si se analizan variables demogrÃ¡ficas.  
- Documentar el pipeline final como objeto serializable (`joblib`) para reproducibilidad.  

---

## ğŸ§  Conclusiones generales

El trabajo demostrÃ³ que la **etapa de codificaciÃ³n** es determinante en el desempeÃ±o del modelo.  
La correcta elecciÃ³n del encoding influye no solo en la precisiÃ³n, sino tambiÃ©n en la interpretabilidad y el costo computacional.  

- Las variables **numÃ©ricas** siguen siendo los predictores mÃ¡s fuertes del ingreso.  
- Las **categÃ³ricas** enriquecen el modelo, especialmente con tÃ©cnicas que condensan informaciÃ³n estadÃ­stica (Target Encoding).  
- La **explicabilidad basada en SHAP** refuerza la transparencia, clave para decisiones de negocio Ã©ticas y auditables.  

El grupo logrÃ³ un **pipeline robusto, modular y reproducible**, alineado con las buenas prÃ¡cticas de *MLOps educativo* y con la filosofÃ­a **CRISP-DM**, mostrando madurez en anÃ¡lisis crÃ­tico y rigor tÃ©cnico.

---

## ğŸ“‹ PrÃ³ximos Pasos (Bonus)

1. **Incorporar CatBoost Encoding** con ajuste de prior y posterior means.  
2. **Analizar interacciones no lineales** entre features categÃ³ricas codificadas usando Partial Dependence Plots.  
3. **Explorar impacto del encoding en modelos lineales vs. no lineales** (Logistic Regression, XGBoost).  
4. **Implementar GridSearchCV para smoothing** y comparar con Bayesian Optimization.  
5. **Extender el pipeline a datasets multiclase** (> 2 clases en target).  
6. **Incorporar monitorizaciÃ³n de drift** de codificaciÃ³n en entornos de streaming.  
7. **Publicar los resultados en un dashboard interactivo (Plotly / Power BI)** para visualizar mÃ©tricas comparativas.  
8. **AÃ±adir documentaciÃ³n automÃ¡tica del pipeline (`sklearn.set_config(display='diagram')`)** para comunicar claramente la arquitectura.  

---


## ğŸ” BONUS â€” ExtensiÃ³n de la prÃ¡ctica (Ames Housing)

**Objetivo.** Replicar y generalizar los aprendizajes de codificaciÃ³n categÃ³rica en un dataset distinto (Ames Housing), transformÃ¡ndolo en un problema de **clasificaciÃ³n binaria** (precio de venta > mediana) y comparando varios esquemas de *encoding* bajo una **arquitectura de pipeline con branching**.

### âœ… Evidencia:
- [**Notebook Bonus (.ipynb)**](../../evidencias/Aurrecochea-PrÃ¡ctica9Bonus.ipynb) .

## Implementa
- **Branching Pipeline (`ColumnTransformer`)**:
  - *One-Hot* para variables de **baja/mediana** cardinalidad.
  - *CatBoost/Target Encoding* con **smoothing** (tuning) para **alta** cardinalidad.
  - *StandardScaler* para numÃ©ricas.
- **Comparativa de codificadores**: One-Hot (all), **Binary**, **Hashing (dimensiÃ³n fija)** y **Branched(Target-like)**.
- **Modelos**: *Logistic Regression* (baseline interpretable) y **HistGradientBoosting** (no lineal).
- **Tuning**: *GridSearchCV* de smoothing (prior/post) y de hiperparÃ¡metros del HGB.
- **Explicabilidad**: exporta **SHAP top features** (opcional) y cuenta de **features finales**.
- **MLOps bÃ¡sico**: guarda **artefactos (`.joblib`)**, **tabla de resultados (`.csv`)**, **reporte de GridSearch** y un **diagrama textual** del pipeline.
- **MonitorizaciÃ³n**: **PSI** de probabilidades (drift simple entre train/test).

> MotivaciÃ³n: evita la **explosiÃ³n dimensional** del One-Hot para cardinalidad alta y sigue la pauta de anÃ¡lisis/comparaciÃ³n de la prÃ¡ctica original.

### ğŸ§ª Resultados (resumen)
- **Branched (CatBoost/Target) + HGB** logra el **mejor balance** entre AUC/Accuracy y dimensionalidad en presencia de categorÃ­as con muchos niveles.
- **Binary/Hash** ofrece lÃ­neas base **compactas** y favorece a *LogReg*; Ãºtiles en escenarios de streaming o memoria restringida.
- **One-Hot (all)** se acerca al mejor AUC cuando la cardinalidad efectiva es baja, a costa de mÃ¡s columnas.

> En la prÃ¡ctica original, One-Hot (baja) y Branched alcanzaron AUC â‰ˆ 0.90 con 30 features, mientras que Target (alta) redujo a 6 features con AUC â‰ˆ 0.83; Label liderÃ³ en AUC pero introduce orden artificial.

### ğŸ“¦ Artefactos generados
- `artifacts/resultados_modelos.csv` â€” tabla comparativa (Accuracy, AUC, F1, tiempo, #features).
- `artifacts/gridsearch_cv_results.csv` â€” *GridSearchCV* completo.
- `artifacts/model_*.joblib` â€” pipelines entrenados (listos para carga).
- `artifacts/pipeline_diagrama.txt` â€” representaciÃ³n textual del pipeline.
- `artifacts/shap_top_features.csv` â€” (opcional) principales features por impacto SHAP.
- `artifacts/monitoring.json` â€” PSI train vs test (drift simple).

### ğŸ“Œ ConclusiÃ³n de la extensiÃ³n
La **arquitectura branched** con *CatBoost/Target Encoding* para alta cardinalidad, mÃ¡s *One-Hot* en baja, consolida un **pipeline escalable, reproducible y explicable**, en lÃ­nea con la **pauta**: experimentar, **comparar** y seleccionar el mÃ©todo que **optimiza el trade-off** entre desempeÃ±o y dimensionalidad para su despliegue.
