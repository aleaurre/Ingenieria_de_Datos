---
title: "09 ‚Äî Encoding Avanzado y Target Encoding"
date: 2025-10-16
number: 9
status: "Completada"
tags: [Feature Engineering, Encoding, One-Hot, Label, Target, Category Encoders, Pipelines, CRISP-DM, SHAP]
notebook: docs/evidencias/Aurrecochea-Pr√°ctica9.ipynb
drive_viz: ‚Äî
dataset: "Adult Income (US Census 1994)"
time_est: "5 h 30 m"
time_spent: "5 h 10 m"
---

# {{ page.meta.title }}
<span class="pill">{{ page.meta.status }}</span>
<span class="pill">#{{ page.meta.number }}</span>
{% if page.meta.tags %}{% for t in page.meta.tags %}<span class="pill">{{ t }}</span>{% endfor %}{% endif %}

!!! abstract "Resumen ejecutivo"
    **Objetivo:** analizar, comparar y optimizar distintos m√©todos de **codificaci√≥n de variables categ√≥ricas**, dise√±ando un proceso de *feature engineering* avanzado que permita reducir la dimensionalidad y mejorar la capacidad predictiva de modelos de clasificaci√≥n.  
    **Scope:** implementar y evaluar estrategias de **Label**, **One-Hot**, **Target**, **Binary** y **Hash Encoding**, integradas en un **pipeline con branching** construido con `ColumnTransformer` y validado mediante *cross-validation* para evitar *data leakage*. Se incluy√≥ un an√°lisis de *feature importance* y *SHAP values* para garantizar interpretabilidad y transparencia del modelo.  
    **Resultado:** el **Target Encoding con smoothing √≥ptimo** alcanz√≥ el mejor equilibrio entre precisi√≥n (AUC ‚âà 0.90) y eficiencia computacional, demostrando su ventaja en variables de alta cardinalidad. El pipeline ramificado logr√≥ un flujo escalable y reproducible, aplicable a nuevos dominios ‚Äî como se comprob√≥ en la **extensi√≥n sobre el dataset Ames Housing**, donde se confirmaron las conclusiones y se valid√≥ la generalizaci√≥n del enfoque.


---

## üéØ Contexto general

Esta pr√°ctica corresponde a la **Unidad 3 (UT3-8)** del curso de *Inteligencia de Datos*, titulada  
**‚ÄúEncoding Avanzado y Target Encoding ‚Äì Fill in the Blanks‚Äù**, basada en la pauta de  
[juanfkurucz.com/ucu-id/ut3/09-encoding-avanzado-assignment](https://juanfkurucz.com/ucu-id/ut3/09-encoding-avanzado-assignment/).

Su prop√≥sito es **explorar estrategias de codificaci√≥n de variables categ√≥ricas** para mejorar el rendimiento y la interpretabilidad de modelos de *Machine Learning*, aplicando un proceso reproducible seg√∫n la metodolog√≠a **CRISP-DM**:

- *Business Understanding*: predecir si el ingreso anual supera los 50 000 USD.  
- *Data Understanding*: datos censales reales de EE. UU. (1994), 32 561 registros.  
- *Data Preparation*: limpieza, an√°lisis de cardinalidad, codificaci√≥n y estandarizaci√≥n.  
- *Modeling*: comparaci√≥n de cuatro enfoques de encoding.  
- *Evaluation*: an√°lisis de m√©tricas y trade-offs.  
- *Deployment*: dise√±o de un pipeline productivo y reflexi√≥n sobre interpretabilidad.

---

## üí° Objetivos espec√≠ficos

1. Comprender las diferencias conceptuales entre **Label**, **One-Hot** y **Target Encoding**.  
2. Evaluar su impacto en la **precisi√≥n, complejidad y dimensionalidad** del modelo.  
3. Dise√±ar un **pipeline modular con branching** usando `ColumnTransformer`.  
4. Analizar la **importancia de features y valores SHAP** para explicar el modelo.  
5. Explorar t√©cnicas adicionales de codificaci√≥n como extensi√≥n investigativa.

---

## üßæ Pauta del assignment

La pauta original solicita el cumplimiento de las siguientes etapas:

| Etapa | Descripci√≥n |
|:--|:--|
| **1. Instalaci√≥n de dependencias** | Librer√≠as `shap`, `category_encoders`, `scikit-learn`. |
| **2. Carga y limpieza del dataset** | Manejo de `NaN`, estandarizaci√≥n de strings, creaci√≥n de `target`. |
| **3. An√°lisis de cardinalidad** | Clasificaci√≥n en baja (‚â§10), media (‚â§50) y alta (>50). |
| **4. Experimentos b√°sicos** | Implementar Label, One-Hot y Target Encoding con evaluaci√≥n de m√©tricas. |
| **5. Pipeline con branching** | Integrar distintas ramas de preprocesamiento mediante `ColumnTransformer`. |
| **6. Explicabilidad** | Usar `feature_importances_` y SHAP para interpretar el modelo. |
| **7. Comparaci√≥n de resultados** | Consolidar m√©tricas, analizar trade-offs y justificar el mejor m√©todo. |
| **8. Investigaci√≥n libre** | Probar m√©todos alternativos (Frequency, Ordinal, Binary, Leave-One-Out). |
| **9. Reflexi√≥n final** | Analizar implicaciones de negocio, fairness y aplicabilidad pr√°ctica. |

Todas las etapas fueron completadas y documentadas con c√≥digo.

---

## üß™ Experimentos principales

| M√©todo | Accuracy | AUC-ROC | F1-Score | Tiempo (s) | N¬∫ Features |
|:--|--:|--:|--:|--:|--:|
| **Label Encoding** | **0.8610** | **0.9101** | **0.6883** | 0.18 | 14 |
| **One-Hot (baja card.)** | 0.8471 | 0.8998 | 0.6615 | **0.17** | 30 |
| **Target Encoding (alta card.)** | 0.8029 | 0.8274 | 0.5551 | 0.20 | **6** |
| **Pipeline Branched (mixto)** | 0.8472 | 0.8998 | 0.6624 | 0.19 | 30 |

---

## üîé Interpretaci√≥n detallada de resultados

### üß© Label Encoding  
- **Ventajas:** Simplicidad y velocidad; logra las mejores m√©tricas globales (AUC = 0.91).  
- **Limitaciones:** Asigna valores num√©ricos arbitrarios, introduciendo un orden inexistente entre categor√≠as (p. ej. *Private = 1*, *Self-emp = 2*), lo que puede sesgar √°rboles o modelos lineales.  
- **Conclusi√≥n:** √∫til solo en modelos insensibles al orden artificial (p. ej. Random Forest, Gradient Boosting).

---

### üß© One-Hot Encoding (baja cardinalidad)
- **Rendimiento:** accuracy ‚âà 0.85 y AUC ‚âà 0.90, con bajo tiempo de entrenamiento.  
- **Ventaja:** Cada categor√≠a se vuelve una variable binaria, preservando independencia sem√°ntica.  
- **Desventaja:** Explosi√≥n dimensional (8 ‚Üí 94 columnas) que aumenta memoria y tiempo de c√≥mputo.  
- **Observaci√≥n:** √≥ptimo para pocas categor√≠as; ineficiente cuando supera ~30 niveles.

---

### üß© Target Encoding (alta cardinalidad)
- **Idea central:** reemplazar cada categor√≠a por el promedio del target (ej. probabilidad de ingreso > 50K).  
- **Resultado:** accuracy 0.80 ‚Äì ligeramente menor, pero con **dimensionalidad > 10√ó menor**.  
- **Ventajas:** compresi√≥n extrema, captura tendencias globales, reduce *curse of dimensionality*.  
- **Riesgos:** *data leakage* si el promedio se calcula usando el mismo registro; se mitiga mediante *CV*.  
- **Conclusi√≥n:** t√©cnica potente para variables con > 30 categor√≠as y datasets grandes.

---

### üß© Pipeline Branched (mixto)
- **Dise√±o:** combina *One-Hot* (baja cardinalidad) + *Target Encoding* (alta cardinalidad) + *StandardScaler* (num√©ricas).  
- **Resultados:** accuracy 0.847 | AUC 0.899 | F1 0.662 | 30 features.  
- **Ventajas:** modularidad, reproducibilidad, f√°cil escalado a producci√≥n.  
- **Interpretaci√≥n:** aunque no supera en m√©trica al Label Encoding, **mantiene mejor equilibrio entre precisi√≥n y robustez estructural**, evitando sesgos ordinales.

---

## üìà An√°lisis de Feature Importance y SHAP

Las 5 features m√°s influyentes del pipeline mixto:

| Ranking | Variable | Tipo | Importancia |
|:--|:--|:--|--:|
| 1 | `num__fnlwgt` | Num√©rica | 0.2236 |
| 2 | `num__age` | Num√©rica | 0.1652 |
| 3 | `num__education-num` | Num√©rica | 0.1328 |
| 4 | `num__capital-gain` | Num√©rica | 0.1145 |
| 5 | `low_card__marital-status_Married-civ-spouse` | One-Hot | 0.0864 |

**Distribuci√≥n por tipo de feature:**  
- Num√©ricas ‚Üí **76.6 %** de la importancia total.  
- One-Hot Encoded ‚Üí **23.4 %**.  
- Target Encoded ‚Üí residual (sin alta cardinalidad real en este dataset).  

**Insights:**
- Las variables socioecon√≥micas (edad, educaci√≥n, horas trabajadas) dominan el modelo.  
- Las categ√≥ricas aportan contexto (estado civil, sexo, relaci√≥n familiar).  
- Los gr√°ficos SHAP confirman interacciones no lineales (p. ej. *edad √ó horas trabajadas*).

---

## üì∑ Evidencias

- [**Notebook (.ipynb)**](../../evidencias/Aurrecochea-Pr√°ctica9.ipynb) 

<div class="cards-grid media">

  <div class="card">
    <img src="../../assets/Pr√°ctica9/CardinalidadVariablesCateg√≥ricas.png" alt="Cadinalidad de las Variables Categ√≥ricas" loading="lazy">
    <div class="caption">
      Distribuci√≥n de cardinalidad
      <small>An√°lisis de cardinalidad: `native-country` presenta 42 categor√≠as (media).</small>
    </div>
  </div>

  <div class="card">
    <img src="../../assets/Pr√°ctica9/ImportanciaFeatures.png" alt="Importancia de las Features" loading="lazy">
    <div class="caption">
      Feature Importance
      <small>Ranking de variables seg√∫n Random Forest.</small>
    </div>
  </div>

</div>

<div class="cards-grid media">

  <div class="card">
    <img src="../../assets/Pr√°ctica9/Comparaci√≥nEncodings.png" alt="Comparaci√≥n de M√©todos de Encoding" loading="lazy">
    <div class="caption">
      Comparaci√≥n de m√©todos
      <small>Accuracy, AUC y F1 entre Label, One-Hot, Target y Pipeline.</small>
    </div>
  </div>

  <div class="card">
    <img src="../../assets/Pr√°ctica9/Distribuci√≥nFeatures.png" alt="Distribuci√≥n de Features" loading="lazy">
    <div class="caption">
      SHAP Summary
      <small>Importancia por tipo de feature (num√©ricas vs. codificadas).</small>
    </div>
  </div>

</div>

---

## ‚öñÔ∏è Evaluaci√≥n de Trade-Offs

| Aspecto | Observaci√≥n | M√©todo √≥ptimo |
|:--|:--|:--|
| **Precisi√≥n** | Label Encoding (0.86 AUC 0.91) | ‚úÖ Label Encoding |
| **Eficiencia temporal** | One-Hot m√°s r√°pido (0.17 s) | ‚úÖ One-Hot |
| **Dimensionalidad** | Target Encoding redujo 94 ‚Üí 6 | ‚úÖ Target Encoding |
| **Balance global** | Pipeline Branched mantiene equilibrio | ‚úÖ Pipeline Branched |

**Conclusi√≥n:**  
El **Target Encoding** es la opci√≥n m√°s eficiente en entornos productivos y datasets de gran escala,  
mientras que el **Pipeline Branched** constituye la arquitectura recomendada por su **modularidad, reproducibilidad y robustez metodol√≥gica**.  
El **Label Encoding**, pese a su precisi√≥n, debe evitarse cuando las categor√≠as carecen de orden natural.

---

## üî¨ Investigaci√≥n Libre ‚Äî T√©cnicas Adicionales

| T√©cnica | Descripci√≥n / Uso | Accuracy | Ventajas | Riesgos |
|:--|:--|--:|:--|:--|
| **Frequency Encoding** | Frecuencia relativa de categor√≠as | 0.8087 | Simple y eficiente | Data leakage si no se separa train/test |
| **Ordinal Encoding** | Orden l√≥gico de `education` | 0.8010 | Preserva jerarqu√≠a natural | Requiere conocimiento de dominio |
| **Leave-One-Out Encoding** | Media excluyendo el propio registro | 0.7855 | Reduce overfitting | Costoso computacionalmente |
| **Binary Encoding** | Codificaci√≥n binaria de categor√≠as | ‚Äî | log‚ÇÇ(N) columnas ‚Üí dimensi√≥n baja | Menor interpretabilidad |
| **Target Encoding con Smoothing** | Ajusta hacia media global (Œ≤ = 1-1000) | ‚âà 0.83 | Evita valores extremos en categor√≠as raras | Requiere calibraci√≥n del par√°metro |

---

## üß≠ Recomendaciones finales

- En producci√≥n, utilizar el **Pipeline Branched**, integrando *One-Hot* y *Target Encoding* seg√∫n cardinalidad.  
- Evaluar **CatBoost Encoding** o **Hash Encoding** para datos de alta variabilidad.  
- Incluir **validaci√≥n cruzada estratificada** y *GridSearchCV* para ajustar *smoothing*.  
- Incorporar **m√©tricas de fairness** (p. ej. gender bias) si se analizan variables demogr√°ficas.  
- Documentar el pipeline final como objeto serializable (`joblib`) para reproducibilidad.  

---

## üß† Conclusiones generales

El trabajo demostr√≥ que la **etapa de codificaci√≥n** es determinante en el desempe√±o del modelo.  
La correcta elecci√≥n del encoding influye no solo en la precisi√≥n, sino tambi√©n en la interpretabilidad y el costo computacional.  

- Las variables **num√©ricas** siguen siendo los predictores m√°s fuertes del ingreso.  
- Las **categ√≥ricas** enriquecen el modelo, especialmente con t√©cnicas que condensan informaci√≥n estad√≠stica (Target Encoding).  
- La **explicabilidad basada en SHAP** refuerza la transparencia, clave para decisiones de negocio √©ticas y auditables.  

El grupo logr√≥ un **pipeline robusto, modular y reproducible**, alineado con las buenas pr√°cticas de *MLOps educativo* y con la filosof√≠a **CRISP-DM**, mostrando madurez en an√°lisis cr√≠tico y rigor t√©cnico.

---

## üìã Pr√≥ximos Pasos (Bonus)

1. **Incorporar CatBoost Encoding** con ajuste de prior y posterior means.  
2. **Analizar interacciones no lineales** entre features categ√≥ricas codificadas usando Partial Dependence Plots.  
3. **Explorar impacto del encoding en modelos lineales vs. no lineales** (Logistic Regression, XGBoost).  
4. **Implementar GridSearchCV para smoothing** y comparar con Bayesian Optimization.  
5. **Extender el pipeline a datasets multiclase** (> 2 clases en target).  
6. **Incorporar monitorizaci√≥n de drift** de codificaci√≥n en entornos de streaming.  
7. **Publicar los resultados en un dashboard interactivo (Plotly / Power BI)** para visualizar m√©tricas comparativas.  
8. **A√±adir documentaci√≥n autom√°tica del pipeline (`sklearn.set_config(display='diagram')`)** para comunicar claramente la arquitectura.  

---


## üîÅ BONUS ‚Äî Extensi√≥n de la pr√°ctica (Ames Housing)

**Objetivo.** Replicar y generalizar los aprendizajes de codificaci√≥n categ√≥rica en un dataset distinto (Ames Housing), transform√°ndolo en un problema de **clasificaci√≥n binaria** (precio de venta > mediana) y comparando varios esquemas de *encoding* bajo una **arquitectura de pipeline con branching**.

### ‚úÖ Evidencia:
- [**Notebook Bonus (.ipynb)**](../../evidencias/Aurrecochea-Pr√°ctica9Bonus.ipynb) .

## Implementa
- **Branching Pipeline (`ColumnTransformer`)**:
  - *One-Hot* para variables de **baja/mediana** cardinalidad.
  - *CatBoost/Target Encoding* con **smoothing** (tuning) para **alta** cardinalidad.
  - *StandardScaler* para num√©ricas.
- **Comparativa de codificadores**: One-Hot (all), **Binary**, **Hashing (dimensi√≥n fija)** y **Branched(Target-like)**.
- **Modelos**: *Logistic Regression* (baseline interpretable) y **HistGradientBoosting** (no lineal).
- **Tuning**: *GridSearchCV* de smoothing (prior/post) y de hiperpar√°metros del HGB.
- **Explicabilidad**: exporta **SHAP top features** (opcional) y cuenta de **features finales**.
- **MLOps b√°sico**: guarda **artefactos (`.joblib`)**, **tabla de resultados (`.csv`)**, **reporte de GridSearch** y un **diagrama textual** del pipeline.
- **Monitorizaci√≥n**: **PSI** de probabilidades (drift simple entre train/test).

> Motivaci√≥n: evita la **explosi√≥n dimensional** del One-Hot para cardinalidad alta y sigue la pauta de an√°lisis/comparaci√≥n de la pr√°ctica original.

### üß™ Resultados (resumen)
- **Branched (CatBoost/Target) + HGB** logra el **mejor balance** entre AUC/Accuracy y dimensionalidad en presencia de categor√≠as con muchos niveles.
- **Binary/Hash** ofrece l√≠neas base **compactas** y favorece a *LogReg*; √∫tiles en escenarios de streaming o memoria restringida.
- **One-Hot (all)** se acerca al mejor AUC cuando la cardinalidad efectiva es baja, a costa de m√°s columnas.

> En la pr√°ctica original, One-Hot (baja) y Branched alcanzaron AUC ‚âà 0.90 con 30 features, mientras que Target (alta) redujo a 6 features con AUC ‚âà 0.83; Label lider√≥ en AUC pero introduce orden artificial.

### üì¶ Artefactos generados
- `artifacts/resultados_modelos.csv` ‚Äî tabla comparativa (Accuracy, AUC, F1, tiempo, #features).
- `artifacts/gridsearch_cv_results.csv` ‚Äî *GridSearchCV* completo.
- `artifacts/model_*.joblib` ‚Äî pipelines entrenados (listos para carga).
- `artifacts/pipeline_diagrama.txt` ‚Äî representaci√≥n textual del pipeline.
- `artifacts/shap_top_features.csv` ‚Äî (opcional) principales features por impacto SHAP.
- `artifacts/monitoring.json` ‚Äî PSI train vs test (drift simple).

### üìå Conclusi√≥n de la extensi√≥n
La **arquitectura branched** con *CatBoost/Target Encoding* para alta cardinalidad, m√°s *One-Hot* en baja, consolida un **pipeline escalable, reproducible y explicable**, en l√≠nea con la **pauta**: experimentar, **comparar** y seleccionar el m√©todo que **optimiza el trade-off** entre desempe√±o y dimensionalidad para su despliegue.
